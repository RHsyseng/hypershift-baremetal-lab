= Accessing the Hosted Cluster
include::_attributes.adoc[]
:profile: telco-hypershift-baremetal-lab

In the previous section we managed to see the control plane for the Hosted Cluster up and running as well as the two bare metal nodes being part of the Hosted Cluster. In this section we will learn how to get access to the Hosted Cluster and will run the required steps to move the Hosted Cluster deployment from `Partial` to `Completed`.

[#getting-hostedcluster-kubeconfig-kubeadmin]
== Getting the Kubeconfig and Kubeadmin user for the Hosted Cluster

We can get the Hosted Cluster credentials from either the Web UI or the CLI, we will see how to get it from both.

[#getting-hostedcluster-kubeconfig-kubeadmin-webui]
=== Getting the Kubeconfig and Kubeadmin via the WebUi

1. Go to the `hosted` cluster view if you're not already on it. You can get back to it by opening the https://console-openshift-console.apps.management.hypershift.lab/[OpenShift Console]. Making sure `All Clusters` is selected and clicking on the cluster named `hosted`.
2. Under `Cluster installation progress` you will see the `Details` section where you can get the Kubeconfig(1) and see the Kubeadmin credentials(2) as well as the OCP Console URL(3).
+
image::hosted-cluster-details1.png[Hosted Cluster Details 1]
+
3. We will see how to use the kubeconfig in the next section, the kubeadmin cannot be used yet since the Hosted Cluster ingress has not been setup and as such the OCP Console is not reachable, that's something that we will fix in the next sections.

[#getting-hostedcluster-kubeconfig-kubeadmin-cli]
=== Getting the Kubeconfig and Kubeadmin via the CLI

1. In order to get the kubeconfig we can run the following command.
+
IMPORTANT: In the command below we're redirecting the output to a file  `~/hypershift-lab/hosted-kubeconfig`.
+
[.console-input]
[source,bash,subs="attributes+,+macros"]
-----
oc --kubeconfig ~/hypershift-lab/mgmt-kubeconfig -n hosted extract secret/hosted-admin-kubeconfig --to=- > ~/hypershift-lab/hosted-kubeconfig
-----
+
2. The kubeadmin password can be retrieved with the command below.
+
[.console-input]
[source,bash,subs="attributes+,+macros"]
-----
oc --kubeconfig ~/hypershift-lab/mgmt-kubeconfig -n hosted extract secret/hosted-kubeadmin-password --to=-
-----
+
IMPORTANT: The password is likely to be different in your environment.
+
[console-input]
[source,console,subs="attributes+,+macros"]
-----
# password
7QzQh-kgUUp-T6Q77-DU8IP
-----

[#accessing-hostedcluster-kubeconfig]
== Accessing the Hosted Cluster using the Kubeconfig

IMPORTANT: Before using the Kubeconfig we need to edit one parameter. This is only required due to the lab setup we have, in a real scenario this change shouldn't be required. We will be changing the kubeconfig's API endpoint from the IP to the DNS record for the API.

[.console-input]
[source,bash,subs="attributes+,+macros"]
-----
sed -i "s/192.168.125.150/api.hosted.hypershift.lab/" ~/hypershift-lab/hosted-kubeconfig
-----

1. We can access the HostedCluster now. We can see two nodes joined the cluster.
+
IMPORTANT: We need to use the `--insecure-skip-tls-verify=true` due to the lab setup we have, in a real scenario this shouldn't be required.
+
[.console-input]
[source,bash,subs="attributes+,+macros"]
-----
oc --insecure-skip-tls-verify=true --kubeconfig ~/hypershift-lab/hosted-kubeconfig get nodes
-----
+
[console-input]
[source,console,subs="attributes+,+macros"]
-----
NAME             STATUS   ROLES    AGE    VERSION
hosted-worker0   Ready    worker   130m   v1.25.8+37a9a08
hosted-worker2   Ready    worker   129m   v1.25.8+37a9a08
-----
+
2. If we check the ClusterVersion it complains about some non-available operators.
+
[.console-input]
[source,bash,subs="attributes+,+macros"]
-----
oc --insecure-skip-tls-verify=true --kubeconfig ~/hypershift-lab/hosted-kubeconfig get clusterversion
-----
+
[console-input]
[source,console,subs="attributes+,+macros"]
-----
NAME      VERSION   AVAILABLE   PROGRESSING   SINCE   STATUS
version             False       True          141m    Unable to apply 4.12.19: the cluster operator console is not available
-----
+
3. The ClusterOperators list will let us know which operators are not ready.
+
[.console-input]
[source,bash,subs="attributes+,+macros"]
-----
oc --insecure-skip-tls-verify=true --kubeconfig ~/hypershift-lab/hosted-kubeconfig get clusteroperators
-----
+
IMPORTANT: We can see `console` and `ingress` operators are not ready. Let's fix that.
+
[console-input]
[source,console,subs="attributes+,+macros"]
-----
NAME                                       VERSION   AVAILABLE   PROGRESSING   DEGRADED   SINCE   MESSAGE
console                                    4.12.19   False       False         False      127m    RouteHealthAvailable: failed to GET route (https://console-openshift-console.apps.hosted.hypershift.lab): Get "https://console-openshift-console.apps.hosted.hypershift.lab": dial tcp 192.168.125.160:443: i/o timeout (Client.Timeout exceeded while awaiting headers)
csi-snapshot-controller                    4.12.19   True        False         False      142m    
dns                                        4.12.19   True        False         False      129m    
image-registry                             4.12.19   True        False         False      129m    
ingress                                    4.12.19   True        False         True       141m    The "default" ingress controller reports Degraded=True: DegradedConditions: One or more other status conditions indicate a degraded state: CanaryChecksSucceeding=False (CanaryChecksRepetitiveFailures: Canary route checks for the default ingress controller are failing)
insights                                   4.12.19   True        False         False      130m    
kube-apiserver                             4.12.19   True        False         False      142m    
kube-controller-manager                    4.12.19   True        False         False      142m    
kube-scheduler                             4.12.19   True        False         False      142m    
kube-storage-version-migrator              4.12.19   True        False         False      129m    
monitoring                                 4.12.19   True        False         False      128m    
network                                    4.12.19   True        False         False      130m    
node-tuning                                4.12.19   True        False         False      133m    
openshift-apiserver                        4.12.19   True        False         False      142m    
openshift-controller-manager               4.12.19   True        False         False      142m    
openshift-samples                          4.12.19   True        False         False      129m    
operator-lifecycle-manager                 4.12.19   True        False         False      141m    
operator-lifecycle-manager-catalog         4.12.19   True        False         False      142m    
operator-lifecycle-manager-packageserver   4.12.19   True        False         False      142m    
service-ca                                 4.12.19   True        False         False      130m    
storage                                    4.12.19   True        False         False      142m  
-----

[#fixing-hostedcluster-ingress]
== Fixing the Hosted Cluster Ingress

In order to provide ingress capabilities to our Hosted Cluster we will use a `LoadBalancer` service. `MetalLB` is required for that, `MetalLB` is outside the scope of this lab, you can learn more about it https://docs.openshift.com/container-platform/4.13/networking/metallb/about-metallb.html[here].

1. Let's get MetalLB Operator deployed.
+
[.console-input]
[source,bash,subs="attributes+,+macros"]
-----
oc --insecure-skip-tls-verify=true --kubeconfig ~/hypershift-lab/hosted-kubeconfig apply -f https://raw.githubusercontent.com/RHsyseng/telco-hypershift-baremetal-lab/lab-4.13/lab-materials/hosted-cluster/metallb-deployment.yaml
sleep 5
oc --insecure-skip-tls-verify=true --kubeconfig ~/hypershift-lab/hosted-kubeconfig -n openshift-operators wait --for=jsonpath='{.status.state}'=AtLatestKnown subscription/metallb-operator
oc --insecure-skip-tls-verify=true --kubeconfig ~/hypershift-lab/hosted-kubeconfig apply -f https://raw.githubusercontent.com/RHsyseng/telco-hypershift-baremetal-lab/lab-4.13/lab-materials/hosted-cluster/metallb-config.yaml
-----
+
[console-input]
[source,console,subs="attributes+,+macros"]
-----
subscription.operators.coreos.com/metallb-operator created
subscription.operators.coreos.com/metallb-operator condition met
metallb.metallb.io/metallb created
ipaddresspool.metallb.io/lab-network created
l2advertisement.metallb.io/advertise-lab-network created
-----
+
2. Create the LoadBalancer service that exposes the OpenShift Routers.
+
[.console-input]
[source,bash,subs="attributes+,+macros"]
-----
cat <<EOF | oc --insecure-skip-tls-verify=true --kubeconfig ~/hypershift-lab/hosted-kubeconfig apply -f -
kind: Service
apiVersion: v1
metadata:
  annotations:
    metallb.universe.tf/address-pool: lab-network
  name: metallb-ingress
  namespace: openshift-ingress
spec:
  ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 80
    - name: https
      protocol: TCP
      port: 443
      targetPort: 443
  selector:
    ingresscontroller.operator.openshift.io/deployment-ingresscontroller: default
  type: LoadBalancer
EOF
-----
+
[console-input]
[source,console,subs="attributes+,+macros"]
-----
service/metallb-ingress created
-----
3. If we check the ClusterVersion finished cluster deployment now.
+
[.console-input]
[source,bash,subs="attributes+,+macros"]
-----
oc --insecure-skip-tls-verify=true --kubeconfig ~/hypershift-lab/hosted-kubeconfig get clusterversion
-----
+
IMPORTANT: It can take up to 5 minutes for the clusterversion to move to complete.
+
[console-input]
[source,console,subs="attributes+,+macros"]
-----
NAME      VERSION   AVAILABLE   PROGRESSING   SINCE   STATUS
version   4.12.19   True        False         10s     Cluster version is 4.12.19
-----
4. Additionally we can check the HostedCluster state on the management cluster.
+
[.console-input]
[source,bash,subs="attributes+,+macros"]
-----
oc --insecure-skip-tls-verify=true --kubeconfig ~/hypershift-lab/mgmt-kubeconfig -n hosted get hostedcluster hosted
-----
+
IMPORTANT: It can take up to 5 minutes for the clusterversion to move to complete.
+
[console-input]
[source,console,subs="attributes+,+macros"]
-----
NAME     VERSION   KUBECONFIG                PROGRESS    AVAILABLE   PROGRESSING   MESSAGE
hosted   4.12.19   hosted-admin-kubeconfig   Completed   True        False         The hosted control plane is available
-----

[#accessing-hostedcluster-ocp-console]
== Accessing the Hosted Cluster using the OCP Console

You can point your browser to https://console-openshift-console.apps.hosted.hypershift.lab/[https://console-openshift-console.apps.hosted.hypershift.lab/] and access using the kubeadmin user and the kubeadmin password we retrieved in a previous step. You should see something similar to the image below.

image::hosted-cluster-ocp-console.png[Hosted Cluster OCP Console]